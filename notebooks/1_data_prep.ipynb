{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NCwQQFkU3v5"
   },
   "source": [
    "### 2.   Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAIO_Y5Z9_Ay"
   },
   "source": [
    "**[2.1]** Import the boto3, pandas and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2VRE9JYD9_Kk"
   },
   "outputs": [],
   "source": [
    "#Solution\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBI4XNtr-eFt"
   },
   "source": [
    "**[2.2]** Create a function that will all files from a S3 bucket contains a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "phCg5b_6-eQY"
   },
   "outputs": [],
   "source": [
    "def list_bucket_contents(bucket, match=''):\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    bucket_resource = s3_resource.Bucket(bucket)\n",
    "    for key in bucket_resource.objects.all():\n",
    "        if match in key.key:\n",
    "            print(key.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2.3]** Call the function you defined to list the file of the 'nyc-tlc' bucket that contains the string '2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gcaDN6V3_3q9",
    "outputId": "03487309-2621-4a9a-a5fc-c825cd0ea68b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip data/fhv_tripdata_2020-01.csv\n",
      "trip data/fhv_tripdata_2020-02.csv\n",
      "trip data/fhv_tripdata_2020-03.csv\n",
      "trip data/fhv_tripdata_2020-04.csv\n",
      "trip data/fhv_tripdata_2020-05.csv\n",
      "trip data/fhv_tripdata_2020-06.csv\n",
      "trip data/fhv_tripdata_2020-07.csv\n",
      "trip data/fhv_tripdata_2020-08.csv\n",
      "trip data/fhv_tripdata_2020-09.csv\n",
      "trip data/fhv_tripdata_2020-10.csv\n",
      "trip data/fhv_tripdata_2020-11.csv\n",
      "trip data/fhv_tripdata_2020-12.csv\n",
      "trip data/fhvhv_tripdata_2020-01.csv\n",
      "trip data/fhvhv_tripdata_2020-02.csv\n",
      "trip data/fhvhv_tripdata_2020-03.csv\n",
      "trip data/fhvhv_tripdata_2020-04.csv\n",
      "trip data/fhvhv_tripdata_2020-05.csv\n",
      "trip data/fhvhv_tripdata_2020-06.csv\n",
      "trip data/fhvhv_tripdata_2020-07.csv\n",
      "trip data/fhvhv_tripdata_2020-08.csv\n",
      "trip data/fhvhv_tripdata_2020-09.csv\n",
      "trip data/fhvhv_tripdata_2020-10.csv\n",
      "trip data/fhvhv_tripdata_2020-11.csv\n",
      "trip data/fhvhv_tripdata_2020-12.csv\n",
      "trip data/green_tripdata_2020-01.csv\n",
      "trip data/green_tripdata_2020-02.csv\n",
      "trip data/green_tripdata_2020-03.csv\n",
      "trip data/green_tripdata_2020-04.csv\n",
      "trip data/green_tripdata_2020-05.csv\n",
      "trip data/green_tripdata_2020-06.csv\n",
      "trip data/green_tripdata_2020-07.csv\n",
      "trip data/green_tripdata_2020-08.csv\n",
      "trip data/green_tripdata_2020-09.csv\n",
      "trip data/green_tripdata_2020-10.csv\n",
      "trip data/green_tripdata_2020-11.csv\n",
      "trip data/green_tripdata_2020-12.csv\n",
      "trip data/yellow_tripdata_2020-01.csv\n",
      "trip data/yellow_tripdata_2020-02.csv\n",
      "trip data/yellow_tripdata_2020-03.csv\n",
      "trip data/yellow_tripdata_2020-04.csv\n",
      "trip data/yellow_tripdata_2020-05.csv\n",
      "trip data/yellow_tripdata_2020-06.csv\n",
      "trip data/yellow_tripdata_2020-07.csv\n",
      "trip data/yellow_tripdata_2020-08.csv\n",
      "trip data/yellow_tripdata_2020-09.csv\n",
      "trip data/yellow_tripdata_2020-10.csv\n",
      "trip data/yellow_tripdata_2020-11.csv\n",
      "trip data/yellow_tripdata_2020-12.csv\n"
     ]
    }
   ],
   "source": [
    "#Solution\n",
    "list_bucket_contents(bucket='nyc-tlc', match='2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-Zy6Oq8pkuB"
   },
   "source": [
    "**[2.4]** Load the file named `trip data/yellow_tripdata_2020-04.csv` into a dataframe called df. Specify `s3://` as prefix for the file url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q1iETWjDftMg",
    "outputId": "6c8de260-a547-4683-c6d8-abfed23db51a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Solution:\n",
    "df = pd.read_csv('s3://nyc-tlc/trip data/yellow_tripdata_2020-04.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLyMcoNCsx2k"
   },
   "source": [
    "**[2.5]** Display the first 5 rows of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xvnbhiPhs0ZP",
    "outputId": "ad54100b-6d70-4cbf-aba5-4aeb6570eae9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-04-01 00:41:22</td>\n",
       "      <td>2020-04-01 01:01:53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-04-01 00:56:00</td>\n",
       "      <td>2020-04-01 01:09:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>95</td>\n",
       "      <td>197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-04-01 00:00:26</td>\n",
       "      <td>2020-04-01 00:09:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>237</td>\n",
       "      <td>137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-04-01 00:24:38</td>\n",
       "      <td>2020-04-01 00:34:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-01 00:13:24</td>\n",
       "      <td>2020-04-01 00:18:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>263</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0       1.0  2020-04-01 00:41:22   2020-04-01 01:01:53              1.0   \n",
       "1       1.0  2020-04-01 00:56:00   2020-04-01 01:09:25              1.0   \n",
       "2       1.0  2020-04-01 00:00:26   2020-04-01 00:09:25              1.0   \n",
       "3       1.0  2020-04-01 00:24:38   2020-04-01 00:34:38              0.0   \n",
       "4       2.0  2020-04-01 00:13:24   2020-04-01 00:18:26              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           1.20         1.0                  N            41            24   \n",
       "1           3.40         1.0                  N            95           197   \n",
       "2           2.80         1.0                  N           237           137   \n",
       "3           2.60         1.0                  N            68           142   \n",
       "4           1.44         1.0                  Y           263            74   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0           2.0          5.5    0.5      0.5        0.00           0.0   \n",
       "1           1.0         12.5    0.5      0.5        2.75           0.0   \n",
       "2           1.0         10.0    3.0      0.5        1.00           0.0   \n",
       "3           1.0         10.0    3.0      0.5        1.00           0.0   \n",
       "4           1.0          6.5    0.5      0.5        3.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3          6.80                   0.0  \n",
       "1                    0.3         16.55                   0.0  \n",
       "2                    0.3         14.80                   2.5  \n",
       "3                    0.3         14.80                   2.5  \n",
       "4                    0.3         13.30                   2.5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQgeYjQDs12m"
   },
   "source": [
    "**[2.6]** Display the dimensions (shape) of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Dg_89DlAs1_w",
    "outputId": "16f8c7cc-03a6-4489-aaac-740f33475335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237993, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyle1PCws7B0"
   },
   "source": [
    "**[2.7]** Display the summary (info) of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l1msvlh7s7Lt",
    "outputId": "78d736f9-ffa8-41ca-d0a4-8a176b917503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 237993 entries, 0 to 237992\n",
      "Data columns (total 18 columns):\n",
      "VendorID                 218480 non-null float64\n",
      "tpep_pickup_datetime     237993 non-null object\n",
      "tpep_dropoff_datetime    237993 non-null object\n",
      "passenger_count          218480 non-null float64\n",
      "trip_distance            237993 non-null float64\n",
      "RatecodeID               218480 non-null float64\n",
      "store_and_fwd_flag       218480 non-null object\n",
      "PULocationID             237993 non-null int64\n",
      "DOLocationID             237993 non-null int64\n",
      "payment_type             218480 non-null float64\n",
      "fare_amount              237993 non-null float64\n",
      "extra                    237993 non-null float64\n",
      "mta_tax                  237993 non-null float64\n",
      "tip_amount               237993 non-null float64\n",
      "tolls_amount             237993 non-null float64\n",
      "improvement_surcharge    237993 non-null float64\n",
      "total_amount             237993 non-null float64\n",
      "congestion_surcharge     237993 non-null float64\n",
      "dtypes: float64(13), int64(2), object(3)\n",
      "memory usage: 32.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWLgqm2YtAgP"
   },
   "source": [
    "**[2.8]** Display the descriptive statistics of df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FQLSaoXltAp-",
    "outputId": "569b388f-a74e-4835-db05-6d7ec96b2fff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>218480.000000</td>\n",
       "      <td>218480.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>218480.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>218480.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "      <td>237993.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.564949</td>\n",
       "      <td>1.296764</td>\n",
       "      <td>4.039981</td>\n",
       "      <td>1.034081</td>\n",
       "      <td>154.908422</td>\n",
       "      <td>150.361414</td>\n",
       "      <td>1.425673</td>\n",
       "      <td>11.666027</td>\n",
       "      <td>1.066739</td>\n",
       "      <td>0.487000</td>\n",
       "      <td>1.530229</td>\n",
       "      <td>0.220504</td>\n",
       "      <td>0.296331</td>\n",
       "      <td>16.408621</td>\n",
       "      <td>1.927536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.495765</td>\n",
       "      <td>0.983595</td>\n",
       "      <td>294.879052</td>\n",
       "      <td>0.865044</td>\n",
       "      <td>70.749496</td>\n",
       "      <td>74.474108</td>\n",
       "      <td>0.555915</td>\n",
       "      <td>11.728767</td>\n",
       "      <td>1.260170</td>\n",
       "      <td>0.094993</td>\n",
       "      <td>2.295523</td>\n",
       "      <td>1.342351</td>\n",
       "      <td>0.045429</td>\n",
       "      <td>13.155858</td>\n",
       "      <td>1.072839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-118.000000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-19.870000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-138.170000</td>\n",
       "      <td>-2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>18.360000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>126501.770000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>903.020000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>117.280000</td>\n",
       "      <td>98.750000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>903.320000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            VendorID  passenger_count  trip_distance     RatecodeID  \\\n",
       "count  218480.000000    218480.000000  237993.000000  218480.000000   \n",
       "mean        1.564949         1.296764       4.039981       1.034081   \n",
       "std         0.495765         0.983595     294.879052       0.865044   \n",
       "min         1.000000         0.000000       0.000000       1.000000   \n",
       "25%         1.000000         1.000000       0.950000       1.000000   \n",
       "50%         2.000000         1.000000       1.740000       1.000000   \n",
       "75%         2.000000         1.000000       3.400000       1.000000   \n",
       "max         2.000000         7.000000  126501.770000      99.000000   \n",
       "\n",
       "        PULocationID   DOLocationID   payment_type    fare_amount  \\\n",
       "count  237993.000000  237993.000000  218480.000000  237993.000000   \n",
       "mean      154.908422     150.361414       1.425673      11.666027   \n",
       "std        70.749496      74.474108       0.555915      11.728767   \n",
       "min         1.000000       1.000000       1.000000    -118.000000   \n",
       "25%        97.000000      75.000000       1.000000       5.500000   \n",
       "50%       143.000000     143.000000       1.000000       8.000000   \n",
       "75%       234.000000     233.000000       2.000000      13.000000   \n",
       "max       265.000000     265.000000       4.000000     903.020000   \n",
       "\n",
       "               extra        mta_tax     tip_amount   tolls_amount  \\\n",
       "count  237993.000000  237993.000000  237993.000000  237993.000000   \n",
       "mean        1.066739       0.487000       1.530229       0.220504   \n",
       "std         1.260170       0.094993       2.295523       1.342351   \n",
       "min        -4.500000      -0.500000      -5.000000     -19.870000   \n",
       "25%         0.000000       0.500000       0.000000       0.000000   \n",
       "50%         0.500000       0.500000       1.000000       0.000000   \n",
       "75%         2.500000       0.500000       2.460000       0.000000   \n",
       "max         7.000000       1.100000     117.280000      98.750000   \n",
       "\n",
       "       improvement_surcharge   total_amount  congestion_surcharge  \n",
       "count          237993.000000  237993.000000         237993.000000  \n",
       "mean                0.296331      16.408621              1.927536  \n",
       "std                 0.045429      13.155858              1.072839  \n",
       "min                -0.300000    -138.170000             -2.500000  \n",
       "25%                 0.300000       9.800000              2.500000  \n",
       "50%                 0.300000      12.800000              2.500000  \n",
       "75%                 0.300000      18.360000              2.500000  \n",
       "max                 0.300000     903.320000              2.500000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aWaMMzBBVC5"
   },
   "source": [
    "**[2.9]** Save the dataframe locally in the `data/raw` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WeiW3cRdBeUV"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df.to_csv('../data/raw/yellow_tripdata_2020-04.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miQ6SiKlscLx"
   },
   "source": [
    "### 3. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtuF1V6ctwn-"
   },
   "source": [
    "**[3.1]** Create a copy of df and save it into a variable called df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HrXR7NCLtwxB"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9nXymg9SxjE"
   },
   "source": [
    "**[3.2]** Launch magic commands to automatically reload modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1fgUxXqsuKZl",
    "outputId": "66809bf0-ac7e-4035-a190-2ddd2e98d670"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7DCMLV6TBjr"
   },
   "source": [
    "**[3.4]** Import your new function `convert_to_date` from `src.features.dates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ICjW0_-4TBvu"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from src.features.dates import convert_to_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvEl7w7GTWfL"
   },
   "source": [
    "**[3.5]** Convert the column `tpep_pickup_datetime`, `tpep_dropoff_datetime` with your function `convert_to_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Xuo9WuYhTWr4"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned = convert_to_date(df_cleaned, ['tpep_pickup_datetime', 'tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1RrTCBRDybQ"
   },
   "source": [
    "**[3.6]** Create a new column `trip_duration` that will corresponds to the diuration of the trip in seconds (difference between `tpep_pickup_datetime` and `tpep_dropoff_datetime`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aezRs9S3Dyl0"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned['trip_duration'] = (df_cleaned['tpep_dropoff_datetime'] - df_cleaned['tpep_pickup_datetime']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pKaCxasERAt"
   },
   "source": [
    "**[3.7]** Convert the `trip_duration` column into 5 different bins with [0, 300, 600, 1800, 300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yDwCmIXvERJO"
   },
   "outputs": [],
   "source": [
    "df_cleaned['trip_duration'] = pd.cut(df_cleaned['trip_duration'], bins=[-1, 300, 600, 1800, 300000], labels=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2v1vLMWTofp"
   },
   "source": [
    "**[3.8]** Extract the month component from `tpep_pickup_datetime` and save the results in the column `tpep_pickup_dayofmonth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dfUpbRYSTopS"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned['tpep_pickup_dayofmonth'] = df_cleaned['tpep_pickup_datetime'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt8YYcHuTsDs"
   },
   "source": [
    "**[3.9]** Extract the hour component from `tpep_pickup_datetime` and save the results in the column `tpep_pickup_hourofday`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "z6isEtGBTsNz"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned['tpep_pickup_hourofday'] = df_cleaned['tpep_pickup_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruXvMIbwTt8E"
   },
   "source": [
    "**[3.10]** Extract the day of week component from `tpep_pickup_datetime` and save the results in the column `tpep_pickup_dayofweek`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kDpsPAW0TuGg"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned['tpep_pickup_dayofweek'] = df_cleaned['tpep_pickup_datetime'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFGEj92zZKUX"
   },
   "source": [
    "**[3.11]** Perform One-Hot encoding on the categorical features (`VendorID`, `RatecodeID`, `store_and_fwd_flag`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HMSXXBBOZKfP"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned = pd.get_dummies(df_cleaned, columns=['VendorID', 'RatecodeID', 'store_and_fwd_flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJSHphplGgjd"
   },
   "source": [
    "**[3.12]** Drop the columns `tpep_pickup_datetime`, `tpep_dropoff_datetime`, `PULocationID`, `DOLocationID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "B4p4isj8Ggr4"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', 'DOLocationID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXQCEL7aG0jp"
   },
   "source": [
    "**[3.13]** Save the prepared dataframe in the `data/interim` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yFkJXP3oG02H"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned.to_csv('../data/interim/yellow_tripdata_2020-04_prepared.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8MNBrC4Zgz6"
   },
   "source": [
    "### 4. Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZz-s-n4S01a"
   },
   "source": [
    "**[4.1]** In the file `src/data/sets.py` create a function called `pop_target` with the following logics:\n",
    "- input parameters: dataframe (`df`), target column name (`target_col`), flag to convert to Numpy array which False by default (`to_numpy`)\n",
    "- logics: extract the target variable from input dataframe, split the input dataframe into training, validation and testing sets from the specified ratio\n",
    "- output parameters: features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Vqf775nbS0pY"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "def pop_target(df, target_col, to_numpy=False):\n",
    "    \"\"\"Extract target variable from dataframe and convert to nympy arrays if required\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe\n",
    "    target_col : str\n",
    "        Name of the target variable\n",
    "    to_numpy : bool\n",
    "        Flag stating to convert to numpy array or not\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame/Numpy array\n",
    "        Subsetted Pandas dataframe containing all features\n",
    "    pd.DataFrame/Numpy array\n",
    "        Subsetted Pandas dataframe containing the target\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    target = df_copy.pop(target_col)\n",
    "    \n",
    "    if to_numpy:\n",
    "        df_copy = df_copy.to_numpy()\n",
    "        target = target.to_numpy()\n",
    "    \n",
    "    return df_copy, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFCSRIyMZuAR"
   },
   "source": [
    "**[4.2]** In the file `src/data/sets.py` create a function called `split_sets_random` with the following logics:\n",
    "- input parameters: dataframe (`df`), target column name (`target_col`), flag to convert to Numoy array (`to_numpy`)\n",
    "- logics: extract the target variable from input dataframe and convert to Numpy araay if needed\n",
    "- output parameters: training, validation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eejq-COGZhCP"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "def split_sets_random(df, target_col, test_ratio=0.2, to_numpy=False):\n",
    "    \"\"\"Split sets randomly\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    target_col : str\n",
    "        Name of the target column\n",
    "    test_ratio : float\n",
    "        Ratio used for the validation and testing sets (default: 0.2)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy Array\n",
    "        Features for the training set\n",
    "    Numpy Array\n",
    "        Target for the training set\n",
    "    Numpy Array\n",
    "        Features for the validation set\n",
    "    Numpy Array\n",
    "        Target for the validation set\n",
    "    Numpy Array\n",
    "        Features for the testing set\n",
    "    Numpy Array\n",
    "        Target for the testing set\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    features, target = pop_target(df=df, target_col=target_col, to_numpy=to_numpy)\n",
    "    \n",
    "    X_data, X_test, y_data, y_test = train_test_split(features, target, test_size=test_ratio, random_state=8)\n",
    "    \n",
    "    val_ratio = test_ratio / (1 - test_ratio)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=val_ratio, random_state=8)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJNZfvA4dJ9X"
   },
   "source": [
    "**[4.3]** Import your new function `split_sets_random` and split the data into several sets as Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "fev4FWAYdU1G"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from src.data.sets import split_sets_random\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(df_cleaned, target_col='trip_duration', test_ratio=0.2, to_numpy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4z3CpwGbd4Fi"
   },
   "source": [
    "**[4.4]** Import save_sets from src.data.sets and save the sets into the folder `data/processed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Mpr1RQkLd4PS"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from src.data.sets import save_sets\n",
    "\n",
    "save_sets(X_train, y_train, X_val, y_val, X_test, y_test, path='../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUEbyrm2ZzhL"
   },
   "source": [
    "### 5. Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faMubeDzZzuX"
   },
   "source": [
    "**[5.1]** in `src.models` folder, create a script called `null.py` ans define a class called `NullModel` with:\n",
    "\n",
    "Attributes\n",
    "    ----------\n",
    "    target_type : str\n",
    "        Type of ML problem (default regression)\n",
    "    y : Numpy Array-like\n",
    "        Target variable\n",
    "    pred_value : Float\n",
    "        Value to be used for prediction\n",
    "    preds : Numpy Array\n",
    "        Predicted array\n",
    "\n",
    "Methods\n",
    "-------\n",
    "    fit(y)\n",
    "        Store the input target variable and calculate the predicted value to be used based on the problem type\n",
    "    predict(y)\n",
    "        Generate the predictions\n",
    "    fit_predict(y)\n",
    "        Perform a fit followed by predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBSoR7LTZz3-"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NullModel:\n",
    "    \"\"\"\n",
    "    Class used as baseline model for both regression and classification\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    target_type : str\n",
    "        Type of ML problem (default regression)\n",
    "    y : Numpy Array-like\n",
    "        Target variable\n",
    "    pred_value : Float\n",
    "        Value to be used for prediction\n",
    "    preds : Numpy Array\n",
    "        Predicted array\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit(y)\n",
    "        Store the input target variable and calculate the predicted value to be used based on the problem type\n",
    "    predict(y)\n",
    "        Generate the predictions\n",
    "    fit_predict(y)\n",
    "        Perform a fit followed by predict\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    def __init__(self, target_type: str = \"regression\"):\n",
    "        self.target_type = target_type\n",
    "        self.y = None\n",
    "        self.pred_value = None\n",
    "        self.preds = None\n",
    "        \n",
    "    def fit(self, y):\n",
    "        self.y = y\n",
    "        if self.target_type == \"regression\":\n",
    "            self.pred_value = y.mean()\n",
    "        else:\n",
    "            from scipy.stats import mode\n",
    "            self.pred_value = mode(y)[0][0]\n",
    "    \n",
    "    def predict(self, y):\n",
    "        self.preds = np.full((len(y), 1), self.pred_value)\n",
    "        return self.preds\n",
    "    \n",
    "    def fit_predict(self, y):\n",
    "        self.fit(y)\n",
    "        return self.predict(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKBNkwgmgVPQ"
   },
   "source": [
    "**[5.2]** Import `NullModel` from `src.models.null`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "5lna_U35gVYR"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from src.models.null import NullModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVnjvNeHpCjC"
   },
   "source": [
    "**[5.3]** Instantiate a `NullModel` with `target_type='classification'` and save it into a variable called `base_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7iuqH-OKpCx0"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "base_model = NullModel(target_type=\"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXG-miufpSm_"
   },
   "source": [
    "**[5.4]** Make a prediction using `fit_predict()` and save the results in a variable called `y_base`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "X9qQmoXLpS5K"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "y_base = base_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORcJNo4ygaRa"
   },
   "source": [
    "**[5.5]** In the `src/models/performance.py` file, create a function called `print_class_perf` with the following logics:\n",
    "- input parameters: predicted target (`y_preds`), actual target (`y_actuals`) and name of the set (`set_name`)\n",
    "- logics: Print the Accuracy and F1 score for the provided data\n",
    "- output parameters: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkXUqKMcgaZN"
   },
   "outputs": [],
   "source": [
    "def print_class_perf(y_preds, y_actuals, set_name=None, average='binary'):\n",
    "    \"\"\"Print the Accuracy and F1 score for the provided data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_preds : Numpy Array\n",
    "        Predicted target\n",
    "    y_actuals : Numpy Array\n",
    "        Actual target\n",
    "    set_name : str\n",
    "        Name of the set to be printed\n",
    "    average : str\n",
    "        Parameter  for F1-score averaging\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    print(f\"Accuracy {set_name}: {accuracy_score(y_actuals, y_preds)}\")\n",
    "    print(f\"F1 {set_name}: {f1_score(y_actuals, y_preds, average=average)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekaUYYjqgfcF"
   },
   "source": [
    "**[5.6]** Display the Accuracy and F1 scores of this baseline model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "h8Jmfhk0MQ0i",
    "outputId": "ae9ab92c-161d-4f21-dec9-186274045cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.34539024475646907\n",
      "F1 Training: 0.17733802015864514\n"
     ]
    }
   ],
   "source": [
    "from src.models.performance import print_class_perf\n",
    "\n",
    "print_class_perf(y_preds=y_base, y_actuals=y_train, set_name='Training', average='weighted')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AdvDSI-Lab3-Exercise1-Solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
